{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "DIOdDVt_ET0D",
        "NZDV8a5TDvfj",
        "rd8DHGOAZiM8"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/P2Enjoy/ia-web3.fr/blob/main/Photomaton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "bIQ3KUy-uRhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Stable Diffusion"
      ],
      "metadata": {
        "id": "DIOdDVt_ET0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "iuYYy5xaaEZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUZ7AqtR-0Yn"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "# SD\n",
        "pip install accelerate==0.22.0 diffusers==0.20.2 gradio==3.39.0 Pillow==10.0.0 torch==2.0.1 transformers==4.33.0 xformers==0.0.21 insightface==0.7.3 controlnet_aux==0.0.6 invisible-watermark==0.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Codeformer"
      ],
      "metadata": {
        "id": "NZDV8a5TDvfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "# Sources\n",
        "git clone https://github.com/sczhou/CodeFormer.git\n",
        "# Set up the environment\n",
        "cd CodeFormer\n",
        "# Install python dependencies\n",
        "pip install -r requirements.txt\n",
        "# Install basicsr\n",
        "python basicsr/setup.py develop"
      ],
      "metadata": {
        "id": "T98RspQSlRO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('CodeFormer')\n",
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.transforms.functional import normalize\n",
        "\n",
        "from basicsr.utils import imwrite, img2tensor, tensor2img\n",
        "from basicsr.utils.download_util import load_file_from_url\n",
        "from facelib.utils.face_restoration_helper import FaceRestoreHelper\n",
        "from facelib.utils.misc import is_gray\n",
        "from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "from basicsr.utils.realesrgan_utils import RealESRGANer\n",
        "\n",
        "from basicsr.utils.registry import ARCH_REGISTRY\n",
        "\n",
        "pretrain_model_url = {\n",
        "    'codeformer': 'https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth',\n",
        "    'detection': 'https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/detection_Resnet50_Final.pth',\n",
        "    'parsing': 'https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/parsing_parsenet.pth',\n",
        "    'realesrgan': 'https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/RealESRGAN_x2plus.pth'\n",
        "}\n",
        "# download weights\n",
        "if not os.path.exists('CodeFormer/weights/CodeFormer/codeformer.pth'):\n",
        "    load_file_from_url(url=pretrain_model_url['codeformer'], model_dir='CodeFormer/weights/CodeFormer', progress=True, file_name=None)\n",
        "if not os.path.exists('CodeFormer/weights/facelib/detection_Resnet50_Final.pth'):\n",
        "    load_file_from_url(url=pretrain_model_url['detection'], model_dir='CodeFormer/weights/facelib', progress=True, file_name=None)\n",
        "if not os.path.exists('CodeFormer/weights/facelib/parsing_parsenet.pth'):\n",
        "    load_file_from_url(url=pretrain_model_url['parsing'], model_dir='CodeFormer/weights/facelib', progress=True, file_name=None)\n",
        "if not os.path.exists('CodeFormer/weights/realesrgan/RealESRGAN_x2plus.pth'):\n",
        "    load_file_from_url(url=pretrain_model_url['realesrgan'], model_dir='CodeFormer/weights/realesrgan', progress=True, file_name=None)"
      ],
      "metadata": {
        "id": "XQQspmPYCUW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set enhancer with RealESRGAN\n",
        "def set_realesrgan():\n",
        "    half = True if torch.cuda.is_available() else False\n",
        "    model = RRDBNet(\n",
        "        num_in_ch=3,\n",
        "        num_out_ch=3,\n",
        "        num_feat=64,\n",
        "        num_block=23,\n",
        "        num_grow_ch=32,\n",
        "        scale=2,\n",
        "    )\n",
        "    upsampler = RealESRGANer(\n",
        "        scale=2,\n",
        "        model_path=\"CodeFormer/weights/realesrgan/RealESRGAN_x2plus.pth\",\n",
        "        model=model,\n",
        "        tile=400,\n",
        "        tile_pad=40,\n",
        "        pre_pad=0,\n",
        "        half=half,\n",
        "    )\n",
        "    return upsampler\n",
        "\n",
        "upsampler = set_realesrgan()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "codeformer_net = ARCH_REGISTRY.get(\"CodeFormer\")(\n",
        "    dim_embd=512,\n",
        "    codebook_size=1024,\n",
        "    n_head=8,\n",
        "    n_layers=9,\n",
        "    connect_list=[\"32\", \"64\", \"128\", \"256\"],\n",
        ").to(device)\n",
        "ckpt_path = \"CodeFormer/weights/CodeFormer/codeformer.pth\"\n",
        "checkpoint = torch.load(ckpt_path)[\"params_ema\"]\n",
        "codeformer_net.load_state_dict(checkpoint)\n",
        "codeformer_net.eval()"
      ],
      "metadata": {
        "id": "0XpDym91D_wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def codeformer(image, face_align, background_enhance, face_upsample, upscale, codeformer_fidelity):\n",
        "    \"\"\"Run a single prediction on the model\"\"\"\n",
        "    try: # global try\n",
        "        # take the default setting for the demo\n",
        "        only_center_face = False\n",
        "        draw_box = False\n",
        "        detection_model = \"retinaface_resnet50\"\n",
        "\n",
        "        print('Inp:', image, background_enhance, face_upsample, upscale, codeformer_fidelity)\n",
        "        face_align = face_align if face_align is not None else True\n",
        "        background_enhance = background_enhance if background_enhance is not None else True\n",
        "        face_upsample = face_upsample if face_upsample is not None else True\n",
        "        upscale = upscale if (upscale is not None and upscale > 0) else 2\n",
        "\n",
        "        has_aligned = not face_align\n",
        "        upscale = 1 if has_aligned else upscale\n",
        "\n",
        "        img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
        "        print('\\timage size:', img.shape)\n",
        "\n",
        "        upscale = int(upscale) # convert type to int\n",
        "        if upscale > 4: # avoid memory exceeded due to too large upscale\n",
        "            upscale = 4\n",
        "        if upscale > 2 and max(img.shape[:2])>1000: # avoid memory exceeded due to too large img resolution\n",
        "            upscale = 2\n",
        "        if max(img.shape[:2]) > 1500: # avoid memory exceeded due to too large img resolution\n",
        "            upscale = 1\n",
        "            background_enhance = False\n",
        "            face_upsample = False\n",
        "\n",
        "        face_helper = FaceRestoreHelper(\n",
        "            upscale,\n",
        "            face_size=512,\n",
        "            crop_ratio=(1, 1),\n",
        "            det_model=detection_model,\n",
        "            save_ext=\"png\",\n",
        "            use_parse=True,\n",
        "            device=device,\n",
        "        )\n",
        "        bg_upsampler = upsampler if background_enhance else None\n",
        "        face_upsampler = upsampler if face_upsample else None\n",
        "\n",
        "        if has_aligned:\n",
        "            # the input faces are already cropped and aligned\n",
        "            img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
        "            face_helper.is_gray = is_gray(img, threshold=5)\n",
        "            if face_helper.is_gray:\n",
        "                print('\\tgrayscale input: True')\n",
        "            face_helper.cropped_faces = [img]\n",
        "        else:\n",
        "            face_helper.read_image(img)\n",
        "            # get face landmarks for each face\n",
        "            num_det_faces = face_helper.get_face_landmarks_5(\n",
        "              only_center_face=only_center_face, resize=640, eye_dist_threshold=5\n",
        "            )\n",
        "            print(f'\\tdetect {num_det_faces} faces')\n",
        "            # align and warp each face\n",
        "            face_helper.align_warp_face()\n",
        "\n",
        "        # face restoration for each cropped face\n",
        "        for idx, cropped_face in enumerate(face_helper.cropped_faces):\n",
        "            # prepare data\n",
        "            cropped_face_t = img2tensor(\n",
        "                cropped_face / 255.0, bgr2rgb=True, float32=True\n",
        "            )\n",
        "            normalize(cropped_face_t, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True)\n",
        "            cropped_face_t = cropped_face_t.unsqueeze(0).to(device)\n",
        "\n",
        "            try:\n",
        "                with torch.no_grad():\n",
        "                    output = codeformer_net(\n",
        "                        cropped_face_t, w=codeformer_fidelity, adain=True\n",
        "                    )[0]\n",
        "                    restored_face = tensor2img(output, rgb2bgr=True, min_max=(-1, 1))\n",
        "                del output\n",
        "                torch.cuda.empty_cache()\n",
        "            except RuntimeError as error:\n",
        "                print(f\"Failed inference for CodeFormer: {error}\")\n",
        "                restored_face = tensor2img(\n",
        "                    cropped_face_t, rgb2bgr=True, min_max=(-1, 1)\n",
        "                )\n",
        "\n",
        "            restored_face = restored_face.astype(\"uint8\")\n",
        "            face_helper.add_restored_face(restored_face)\n",
        "\n",
        "        # paste_back\n",
        "        if not has_aligned:\n",
        "            # upsample the background\n",
        "            if bg_upsampler is not None:\n",
        "                # Now only support RealESRGAN for upsampling background\n",
        "                bg_img = bg_upsampler.enhance(img, outscale=upscale)[0]\n",
        "            else:\n",
        "                bg_img = None\n",
        "            face_helper.get_inverse_affine(None)\n",
        "            # paste each restored face to the input image\n",
        "            if face_upsample and face_upsampler is not None:\n",
        "                restored_img = face_helper.paste_faces_to_input_image(\n",
        "                    upsample_img=bg_img,\n",
        "                    draw_box=draw_box,\n",
        "                    face_upsampler=face_upsampler,\n",
        "                )\n",
        "            else:\n",
        "                restored_img = face_helper.paste_faces_to_input_image(\n",
        "                    upsample_img=bg_img, draw_box=draw_box\n",
        "                )\n",
        "        else:\n",
        "            restored_img = restored_face\n",
        "\n",
        "        # save restored img\n",
        "        save_path = f'output/out.png'\n",
        "        imwrite(restored_img, str(save_path))\n",
        "\n",
        "        restored_img = cv2.cvtColor(restored_img, cv2.COLOR_BGR2RGB)\n",
        "        return PIL.Image.fromarray(restored_img)\n",
        "    except Exception as error:\n",
        "        print('Global exception', error)\n",
        "        return None, None"
      ],
      "metadata": {
        "id": "1cQsjTgFEjVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Roop"
      ],
      "metadata": {
        "id": "rd8DHGOAZiM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "pip install insightface==0.7.3 onnx==1.14.0 onnxruntime==1.15.0"
      ],
      "metadata": {
        "id": "0uNmwT8aZmYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "models_dir = os.path.abspath(\"models/onnx\")\n",
        "model_url = \"https://github.com/P2Enjoy/ia-web3.fr/releases/download/onnx_checkpoint/model.onnx\"\n",
        "model_name = os.path.basename(model_url)\n",
        "model_path = os.path.join(models_dir, model_name)"
      ],
      "metadata": {
        "id": "I0v-3xAHbAcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "def download(url, path):\n",
        "    request = urllib.request.urlopen(url)\n",
        "    total = int(request.headers.get('Content-Length', 0))\n",
        "    with tqdm(total=total, desc='Downloading', unit='B', unit_scale=True, unit_divisor=1024) as progress:\n",
        "        urllib.request.urlretrieve(url, path, reporthook=lambda count, block_size, total_size: progress.update(block_size))\n",
        "\n",
        "if not os.path.exists(models_dir):\n",
        "    os.makedirs(models_dir)\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    download(model_url, model_path)"
      ],
      "metadata": {
        "id": "lti1qML3aHFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "def get_models():\n",
        "    models_path = os.path.join('./', \"models\" + os.path.sep + \"onnx\" + os.path.sep + \"*\")\n",
        "    models = glob.glob(models_path)\n",
        "    models = [x for x in models if x.endswith(\".onnx\") or x.endswith(\".pth\")]\n",
        "    return models\n",
        "\n",
        "\n",
        "import copy\n",
        "import math\n",
        "import tempfile\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Union, Dict, Set, Tuple\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import insightface\n",
        "import onnxruntime\n",
        "\n",
        "providers = onnxruntime.get_available_providers()\n",
        "\n",
        "\n",
        "def getModel(model_path: str):\n",
        "  return insightface.model_zoo.get_model(model_path, providers=providers);\n",
        "\n",
        "\n",
        "def getLandmarks(img_data: np.ndarray, face_index=0, det_size=(640, 640)):\n",
        "    face_analyser = insightface.app.FaceAnalysis(name=\"buffalo_l\", providers=providers)\n",
        "    face_analyser.prepare(ctx_id=0, det_size=det_size)\n",
        "    face = face_analyser.get(img_data)\n",
        "\n",
        "    if len(face) == 0 and det_size[0] > 320 and det_size[1] > 320:\n",
        "        det_size_half = (det_size[0] // 2, det_size[1] // 2)\n",
        "        return getLandmarks(img_data, face_index=face_index, det_size=det_size_half)\n",
        "\n",
        "    try:\n",
        "        return sorted(face, key=lambda x: x.bbox[0])[face_index]\n",
        "    except IndexError:\n",
        "        return None"
      ],
      "metadata": {
        "id": "7qLlgkxzbg-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def swap_landmarks(\n",
        "    source_img: Image.Image,\n",
        "    target_img: Image.Image,\n",
        "    model_path: Union[str, None] = None,\n",
        "    faces_index: Set[int] = {0}\n",
        ") -> Image.Image:\n",
        "    result_image = target_img\n",
        "    if model_path is not None:\n",
        "        source_img = cv2.cvtColor(np.array(source_img), cv2.COLOR_RGB2BGR)\n",
        "        target_img = cv2.cvtColor(np.array(target_img), cv2.COLOR_RGB2BGR)\n",
        "        source_face = getLandmarks(source_img, face_index=0)\n",
        "        if source_face is not None:\n",
        "            result = target_img\n",
        "            face_swapper = getModel(model_path)\n",
        "            for face_num in faces_index:\n",
        "                target_face = getLandmarks(target_img, face_index=face_num)\n",
        "                if target_face is not None:\n",
        "                    result = face_swapper.get(result, target_face, source_face)\n",
        "                else:\n",
        "                    print(f\"No target face found for {face_num}\")\n",
        "\n",
        "            result_image = Image.fromarray(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
        "        else:\n",
        "            print(\"No source face found\")\n",
        "\n",
        "    return result_image"
      ],
      "metadata": {
        "id": "AzhVt4Y5cucE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "i_NYAOQ3D327"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load libraries in memory\n",
        "\n",
        "import os\n",
        "import random\n",
        "import gc\n",
        "import numpy as np\n",
        "import torch\n",
        "import PIL.Image\n",
        "\n",
        "from __future__ import annotations\n",
        "from diffusers.models import AutoencoderKL\n",
        "from diffusers.utils import load_image\n",
        "from diffusers import (\n",
        "    ControlNetModel,\n",
        "    StableDiffusionControlNetPipeline,\n",
        "    StableDiffusionXLImg2ImgPipeline,\n",
        "    DiffusionPipeline,\n",
        "    DDIMScheduler, LMSDiscreteScheduler, PNDMScheduler, UniPCMultistepScheduler\n",
        ")\n",
        "from xformers.ops import MemoryEfficientAttentionFlashAttentionOp"
      ],
      "metadata": {
        "id": "Qe836LI4gZTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Custom StableDiffusionPipeline to implement adain cross-attn hack (estimate age, mass, gender from webcam)\n",
        "\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import torch\n",
        "\n",
        "from diffusers import StableDiffusionControlNetPipeline\n",
        "from diffusers.models import ControlNetModel\n",
        "from diffusers.models.attention import BasicTransformerBlock\n",
        "from diffusers.models.unet_2d_blocks import CrossAttnDownBlock2D, CrossAttnUpBlock2D, DownBlock2D, UpBlock2D\n",
        "from diffusers.pipelines.controlnet.multicontrolnet import MultiControlNetModel\n",
        "from diffusers.pipelines.stable_diffusion import StableDiffusionPipelineOutput\n",
        "from diffusers.utils import is_compiled_module, logging, randn_tensor\n",
        "\n",
        "\n",
        "logger = logging.get_logger(__name__)  # pylint: disable=invalid-name\n",
        "\n",
        "EXAMPLE_DOC_STRING = \"\"\"\n",
        "    Examples:\n",
        "        ```py\n",
        "        >>> import cv2\n",
        "        >>> import torch\n",
        "        >>> import numpy as np\n",
        "        >>> from PIL import Image\n",
        "        >>> from diffusers import UniPCMultistepScheduler\n",
        "        >>> from diffusers.utils import load_image\n",
        "\n",
        "        >>> input_image = load_image(\"https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/input_image_vermeer.png\")\n",
        "\n",
        "        >>> # get canny image\n",
        "        >>> image = cv2.Canny(np.array(input_image), 100, 200)\n",
        "        >>> image = image[:, :, None]\n",
        "        >>> image = np.concatenate([image, image, image], axis=2)\n",
        "        >>> canny_image = Image.fromarray(image)\n",
        "\n",
        "        >>> controlnet = ControlNetModel.from_pretrained(\"lllyasviel/sd-controlnet-canny\", torch_dtype=torch.float16)\n",
        "        >>> pipe = StableDiffusionControlNetReferencePipeline.from_pretrained(\n",
        "                \"runwayml/stable-diffusion-v1-5\",\n",
        "                controlnet=controlnet,\n",
        "                safety_checker=None,\n",
        "                torch_dtype=torch.float16\n",
        "                ).to('cuda:0')\n",
        "\n",
        "        >>> pipe.scheduler = UniPCMultistepScheduler.from_config(pipe_controlnet.scheduler.config)\n",
        "\n",
        "        >>> result_img = pipe(ref_image=input_image,\n",
        "                        prompt=\"1girl\",\n",
        "                        image=canny_image,\n",
        "                        num_inference_steps=20,\n",
        "                        reference_attn=True,\n",
        "                        reference_adain=True).images[0]\n",
        "\n",
        "        >>> result_img.show()\n",
        "        ```\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def torch_dfs(model: torch.nn.Module):\n",
        "    result = [model]\n",
        "    for child in model.children():\n",
        "        result += torch_dfs(child)\n",
        "    return result\n",
        "\n",
        "\n",
        "class StableDiffusionControlNetReferencePipeline(StableDiffusionControlNetPipeline):\n",
        "    def prepare_ref_latents(self, refimage, batch_size, dtype, device, generator, do_classifier_free_guidance):\n",
        "        refimage = refimage.to(device=device, dtype=dtype)\n",
        "\n",
        "        # encode the mask image into latents space so we can concatenate it to the latents\n",
        "        if isinstance(generator, list):\n",
        "            ref_image_latents = [\n",
        "                self.vae.encode(refimage[i : i + 1]).latent_dist.sample(generator=generator[i])\n",
        "                for i in range(batch_size)\n",
        "            ]\n",
        "            ref_image_latents = torch.cat(ref_image_latents, dim=0)\n",
        "        else:\n",
        "            ref_image_latents = self.vae.encode(refimage).latent_dist.sample(generator=generator)\n",
        "        ref_image_latents = self.vae.config.scaling_factor * ref_image_latents\n",
        "\n",
        "        # duplicate mask and ref_image_latents for each generation per prompt, using mps friendly method\n",
        "        if ref_image_latents.shape[0] < batch_size:\n",
        "            if not batch_size % ref_image_latents.shape[0] == 0:\n",
        "                raise ValueError(\n",
        "                    \"The passed images and the required batch size don't match. Images are supposed to be duplicated\"\n",
        "                    f\" to a total batch size of {batch_size}, but {ref_image_latents.shape[0]} images were passed.\"\n",
        "                    \" Make sure the number of images that you pass is divisible by the total requested batch size.\"\n",
        "                )\n",
        "            ref_image_latents = ref_image_latents.repeat(batch_size // ref_image_latents.shape[0], 1, 1, 1)\n",
        "\n",
        "        ref_image_latents = torch.cat([ref_image_latents] * 2) if do_classifier_free_guidance else ref_image_latents\n",
        "\n",
        "        # aligning device to prevent device errors when concating it with the latent model input\n",
        "        ref_image_latents = ref_image_latents.to(device=device, dtype=dtype)\n",
        "        return ref_image_latents\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def __call__(\n",
        "        self,\n",
        "        prompt: Union[str, List[str]] = None,\n",
        "        image: Union[\n",
        "            torch.FloatTensor,\n",
        "            PIL.Image.Image,\n",
        "            np.ndarray,\n",
        "            List[torch.FloatTensor],\n",
        "            List[PIL.Image.Image],\n",
        "            List[np.ndarray],\n",
        "        ] = None,\n",
        "        ref_image: Union[torch.FloatTensor, PIL.Image.Image] = None,\n",
        "        height: Optional[int] = None,\n",
        "        width: Optional[int] = None,\n",
        "        num_inference_steps: int = 50,\n",
        "        guidance_scale: float = 7.5,\n",
        "        negative_prompt: Optional[Union[str, List[str]]] = None,\n",
        "        num_images_per_prompt: Optional[int] = 1,\n",
        "        eta: float = 0.0,\n",
        "        generator: Optional[Union[torch.Generator, List[torch.Generator]]] = None,\n",
        "        latents: Optional[torch.FloatTensor] = None,\n",
        "        prompt_embeds: Optional[torch.FloatTensor] = None,\n",
        "        negative_prompt_embeds: Optional[torch.FloatTensor] = None,\n",
        "        output_type: Optional[str] = \"pil\",\n",
        "        return_dict: bool = True,\n",
        "        callback: Optional[Callable[[int, int, torch.FloatTensor], None]] = None,\n",
        "        callback_steps: int = 1,\n",
        "        cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
        "        controlnet_conditioning_scale: Union[float, List[float]] = 1.0,\n",
        "        guess_mode: bool = False,\n",
        "        attention_auto_machine_weight: float = 1.0,\n",
        "        gn_auto_machine_weight: float = 1.0,\n",
        "        style_fidelity: float = 0.5,\n",
        "        reference_attn: bool = True,\n",
        "        reference_adain: bool = True,\n",
        "    ):\n",
        "        r\"\"\"\n",
        "        Function invoked when calling the pipeline for generation.\n",
        "\n",
        "        Args:\n",
        "            prompt (`str` or `List[str]`, *optional*):\n",
        "                The prompt or prompts to guide the image generation. If not defined, one has to pass `prompt_embeds`.\n",
        "                instead.\n",
        "            image (`torch.FloatTensor`, `PIL.Image.Image`, `np.ndarray`, `List[torch.FloatTensor]`, `List[PIL.Image.Image]`, `List[np.ndarray]`,:\n",
        "                    `List[List[torch.FloatTensor]]`, `List[List[np.ndarray]]` or `List[List[PIL.Image.Image]]`):\n",
        "                The ControlNet input condition. ControlNet uses this input condition to generate guidance to Unet. If\n",
        "                the type is specified as `Torch.FloatTensor`, it is passed to ControlNet as is. `PIL.Image.Image` can\n",
        "                also be accepted as an image. The dimensions of the output image defaults to `image`'s dimensions. If\n",
        "                height and/or width are passed, `image` is resized according to them. If multiple ControlNets are\n",
        "                specified in init, images must be passed as a list such that each element of the list can be correctly\n",
        "                batched for input to a single controlnet.\n",
        "            ref_image (`torch.FloatTensor`, `PIL.Image.Image`):\n",
        "                The Reference Control input condition. Reference Control uses this input condition to generate guidance to Unet. If\n",
        "                the type is specified as `Torch.FloatTensor`, it is passed to Reference Control as is. `PIL.Image.Image` can\n",
        "                also be accepted as an image.\n",
        "            height (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor):\n",
        "                The height in pixels of the generated image.\n",
        "            width (`int`, *optional*, defaults to self.unet.config.sample_size * self.vae_scale_factor):\n",
        "                The width in pixels of the generated image.\n",
        "            num_inference_steps (`int`, *optional*, defaults to 50):\n",
        "                The number of denoising steps. More denoising steps usually lead to a higher quality image at the\n",
        "                expense of slower inference.\n",
        "            guidance_scale (`float`, *optional*, defaults to 7.5):\n",
        "                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).\n",
        "                `guidance_scale` is defined as `w` of equation 2. of [Imagen\n",
        "                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale >\n",
        "                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,\n",
        "                usually at the expense of lower image quality.\n",
        "            negative_prompt (`str` or `List[str]`, *optional*):\n",
        "                The prompt or prompts not to guide the image generation. If not defined, one has to pass\n",
        "                `negative_prompt_embeds` instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is\n",
        "                less than `1`).\n",
        "            num_images_per_prompt (`int`, *optional*, defaults to 1):\n",
        "                The number of images to generate per prompt.\n",
        "            eta (`float`, *optional*, defaults to 0.0):\n",
        "                Corresponds to parameter eta () in the DDIM paper: https://arxiv.org/abs/2010.02502. Only applies to\n",
        "                [`schedulers.DDIMScheduler`], will be ignored for others.\n",
        "            generator (`torch.Generator` or `List[torch.Generator]`, *optional*):\n",
        "                One or a list of [torch generator(s)](https://pytorch.org/docs/stable/generated/torch.Generator.html)\n",
        "                to make generation deterministic.\n",
        "            latents (`torch.FloatTensor`, *optional*):\n",
        "                Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image\n",
        "                generation. Can be used to tweak the same generation with different prompts. If not provided, a latents\n",
        "                tensor will ge generated by sampling using the supplied random `generator`.\n",
        "            prompt_embeds (`torch.FloatTensor`, *optional*):\n",
        "                Pre-generated text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not\n",
        "                provided, text embeddings will be generated from `prompt` input argument.\n",
        "            negative_prompt_embeds (`torch.FloatTensor`, *optional*):\n",
        "                Pre-generated negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt\n",
        "                weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt` input\n",
        "                argument.\n",
        "            output_type (`str`, *optional*, defaults to `\"pil\"`):\n",
        "                The output format of the generate image. Choose between\n",
        "                [PIL](https://pillow.readthedocs.io/en/stable/): `PIL.Image.Image` or `np.array`.\n",
        "            return_dict (`bool`, *optional*, defaults to `True`):\n",
        "                Whether or not to return a [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] instead of a\n",
        "                plain tuple.\n",
        "            callback (`Callable`, *optional*):\n",
        "                A function that will be called every `callback_steps` steps during inference. The function will be\n",
        "                called with the following arguments: `callback(step: int, timestep: int, latents: torch.FloatTensor)`.\n",
        "            callback_steps (`int`, *optional*, defaults to 1):\n",
        "                The frequency at which the `callback` function will be called. If not specified, the callback will be\n",
        "                called at every step.\n",
        "            cross_attention_kwargs (`dict`, *optional*):\n",
        "                A kwargs dictionary that if specified is passed along to the `AttentionProcessor` as defined under\n",
        "                `self.processor` in\n",
        "                [diffusers.models.attention_processor](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).\n",
        "            controlnet_conditioning_scale (`float` or `List[float]`, *optional*, defaults to 1.0):\n",
        "                The outputs of the controlnet are multiplied by `controlnet_conditioning_scale` before they are added\n",
        "                to the residual in the original unet. If multiple ControlNets are specified in init, you can set the\n",
        "                corresponding scale as a list.\n",
        "            guess_mode (`bool`, *optional*, defaults to `False`):\n",
        "                In this mode, the ControlNet encoder will try best to recognize the content of the input image even if\n",
        "                you remove all prompts. The `guidance_scale` between 3.0 and 5.0 is recommended.\n",
        "            attention_auto_machine_weight (`float`):\n",
        "                Weight of using reference query for self attention's context.\n",
        "                If attention_auto_machine_weight=1.0, use reference query for all self attention's context.\n",
        "            gn_auto_machine_weight (`float`):\n",
        "                Weight of using reference adain. If gn_auto_machine_weight=2.0, use all reference adain plugins.\n",
        "            style_fidelity (`float`):\n",
        "                style fidelity of ref_uncond_xt. If style_fidelity=1.0, control more important,\n",
        "                elif style_fidelity=0.0, prompt more important, else balanced.\n",
        "            reference_attn (`bool`):\n",
        "                Whether to use reference query for self attention's context.\n",
        "            reference_adain (`bool`):\n",
        "                Whether to use reference adain.\n",
        "\n",
        "        Examples:\n",
        "\n",
        "        Returns:\n",
        "            [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] or `tuple`:\n",
        "            [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] if `return_dict` is True, otherwise a `tuple.\n",
        "            When returning a tuple, the first element is a list with the generated images, and the second element is a\n",
        "            list of `bool`s denoting whether the corresponding generated image likely represents \"not-safe-for-work\"\n",
        "            (nsfw) content, according to the `safety_checker`.\n",
        "        \"\"\"\n",
        "        assert reference_attn or reference_adain, \"`reference_attn` or `reference_adain` must be True.\"\n",
        "\n",
        "# heck_inputs(self, prompt, image, callback_steps, negative_prompt, prompt_embeds, negative_prompt_embeds, controlnet_conditioning_scale, control_guidance_start, control_guidance_end)\n",
        "        # 1. Check inputs. Raise error if not correct\n",
        "        self.check_inputs(\n",
        "            prompt,\n",
        "            image,\n",
        "            callback_steps,\n",
        "            negative_prompt,\n",
        "            prompt_embeds,\n",
        "            negative_prompt_embeds,\n",
        "            controlnet_conditioning_scale,\n",
        "            [0.0],\n",
        "            [1.0]\n",
        "        )\n",
        "\n",
        "        # 2. Define call parameters\n",
        "        if prompt is not None and isinstance(prompt, str):\n",
        "            batch_size = 1\n",
        "        elif prompt is not None and isinstance(prompt, list):\n",
        "            batch_size = len(prompt)\n",
        "        else:\n",
        "            batch_size = prompt_embeds.shape[0]\n",
        "\n",
        "        device = self._execution_device\n",
        "        # here `guidance_scale` is defined analog to the guidance weight `w` of equation (2)\n",
        "        # of the Imagen paper: https://arxiv.org/pdf/2205.11487.pdf . `guidance_scale = 1`\n",
        "        # corresponds to doing no classifier free guidance.\n",
        "        do_classifier_free_guidance = guidance_scale > 1.0\n",
        "\n",
        "        controlnet = self.controlnet._orig_mod if is_compiled_module(self.controlnet) else self.controlnet\n",
        "\n",
        "        if isinstance(controlnet, MultiControlNetModel) and isinstance(controlnet_conditioning_scale, float):\n",
        "            controlnet_conditioning_scale = [controlnet_conditioning_scale] * len(controlnet.nets)\n",
        "\n",
        "        global_pool_conditions = (\n",
        "            controlnet.config.global_pool_conditions\n",
        "            if isinstance(controlnet, ControlNetModel)\n",
        "            else controlnet.nets[0].config.global_pool_conditions\n",
        "        )\n",
        "        guess_mode = guess_mode or global_pool_conditions\n",
        "\n",
        "        # 3. Encode input prompt\n",
        "        text_encoder_lora_scale = (\n",
        "            cross_attention_kwargs.get(\"scale\", None) if cross_attention_kwargs is not None else None\n",
        "        )\n",
        "        prompt_embeds = self._encode_prompt(\n",
        "            prompt,\n",
        "            device,\n",
        "            num_images_per_prompt,\n",
        "            do_classifier_free_guidance,\n",
        "            negative_prompt,\n",
        "            prompt_embeds=prompt_embeds,\n",
        "            negative_prompt_embeds=negative_prompt_embeds,\n",
        "            lora_scale=text_encoder_lora_scale,\n",
        "        )\n",
        "\n",
        "        # 4. Prepare image\n",
        "        if isinstance(controlnet, ControlNetModel):\n",
        "            image = self.prepare_image(\n",
        "                image=image,\n",
        "                width=width,\n",
        "                height=height,\n",
        "                batch_size=batch_size * num_images_per_prompt,\n",
        "                num_images_per_prompt=num_images_per_prompt,\n",
        "                device=device,\n",
        "                dtype=controlnet.dtype,\n",
        "                do_classifier_free_guidance=do_classifier_free_guidance,\n",
        "                guess_mode=guess_mode,\n",
        "            )\n",
        "            height, width = image.shape[-2:]\n",
        "        elif isinstance(controlnet, MultiControlNetModel):\n",
        "            images = []\n",
        "\n",
        "            for image_ in image:\n",
        "                image_ = self.prepare_image(\n",
        "                    image=image_,\n",
        "                    width=width,\n",
        "                    height=height,\n",
        "                    batch_size=batch_size * num_images_per_prompt,\n",
        "                    num_images_per_prompt=num_images_per_prompt,\n",
        "                    device=device,\n",
        "                    dtype=controlnet.dtype,\n",
        "                    do_classifier_free_guidance=do_classifier_free_guidance,\n",
        "                    guess_mode=guess_mode,\n",
        "                )\n",
        "\n",
        "                images.append(image_)\n",
        "\n",
        "            image = images\n",
        "            height, width = image[0].shape[-2:]\n",
        "        else:\n",
        "            assert False\n",
        "\n",
        "        # 5. Preprocess reference image\n",
        "        ref_image = self.prepare_image(\n",
        "            image=ref_image,\n",
        "            width=width,\n",
        "            height=height,\n",
        "            batch_size=batch_size * num_images_per_prompt,\n",
        "            num_images_per_prompt=num_images_per_prompt,\n",
        "            device=device,\n",
        "            dtype=prompt_embeds.dtype,\n",
        "        )\n",
        "\n",
        "        # 6. Prepare timesteps\n",
        "        self.scheduler.set_timesteps(num_inference_steps, device=device)\n",
        "        timesteps = self.scheduler.timesteps\n",
        "\n",
        "        # 7. Prepare latent variables\n",
        "        num_channels_latents = self.unet.config.in_channels\n",
        "        latents = self.prepare_latents(\n",
        "            batch_size * num_images_per_prompt,\n",
        "            num_channels_latents,\n",
        "            height,\n",
        "            width,\n",
        "            prompt_embeds.dtype,\n",
        "            device,\n",
        "            generator,\n",
        "            latents,\n",
        "        )\n",
        "\n",
        "        # 8. Prepare reference latent variables\n",
        "        ref_image_latents = self.prepare_ref_latents(\n",
        "            ref_image,\n",
        "            batch_size * num_images_per_prompt,\n",
        "            prompt_embeds.dtype,\n",
        "            device,\n",
        "            generator,\n",
        "            do_classifier_free_guidance,\n",
        "        )\n",
        "\n",
        "        # 9. Prepare extra step kwargs. TODO: Logic should ideally just be moved out of the pipeline\n",
        "        extra_step_kwargs = self.prepare_extra_step_kwargs(generator, eta)\n",
        "\n",
        "        # 9. Modify self attention and group norm\n",
        "        MODE = \"write\"\n",
        "        uc_mask = (\n",
        "            torch.Tensor([1] * batch_size * num_images_per_prompt + [0] * batch_size * num_images_per_prompt)\n",
        "            .type_as(ref_image_latents)\n",
        "            .bool()\n",
        "        )\n",
        "\n",
        "        def hacked_basic_transformer_inner_forward(\n",
        "            self,\n",
        "            hidden_states: torch.FloatTensor,\n",
        "            attention_mask: Optional[torch.FloatTensor] = None,\n",
        "            encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "            encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "            timestep: Optional[torch.LongTensor] = None,\n",
        "            cross_attention_kwargs: Dict[str, Any] = None,\n",
        "            class_labels: Optional[torch.LongTensor] = None,\n",
        "        ):\n",
        "            if self.use_ada_layer_norm:\n",
        "                norm_hidden_states = self.norm1(hidden_states, timestep)\n",
        "            elif self.use_ada_layer_norm_zero:\n",
        "                norm_hidden_states, gate_msa, shift_mlp, scale_mlp, gate_mlp = self.norm1(\n",
        "                    hidden_states, timestep, class_labels, hidden_dtype=hidden_states.dtype\n",
        "                )\n",
        "            else:\n",
        "                norm_hidden_states = self.norm1(hidden_states)\n",
        "\n",
        "            # 1. Self-Attention\n",
        "            cross_attention_kwargs = cross_attention_kwargs if cross_attention_kwargs is not None else {}\n",
        "            if self.only_cross_attention:\n",
        "                attn_output = self.attn1(\n",
        "                    norm_hidden_states,\n",
        "                    encoder_hidden_states=encoder_hidden_states if self.only_cross_attention else None,\n",
        "                    attention_mask=attention_mask,\n",
        "                    **cross_attention_kwargs,\n",
        "                )\n",
        "            else:\n",
        "                if MODE == \"write\":\n",
        "                    self.bank.append(norm_hidden_states.detach().clone())\n",
        "                    attn_output = self.attn1(\n",
        "                        norm_hidden_states,\n",
        "                        encoder_hidden_states=encoder_hidden_states if self.only_cross_attention else None,\n",
        "                        attention_mask=attention_mask,\n",
        "                        **cross_attention_kwargs,\n",
        "                    )\n",
        "                if MODE == \"read\":\n",
        "                    if attention_auto_machine_weight > self.attn_weight:\n",
        "                        attn_output_uc = self.attn1(\n",
        "                            norm_hidden_states,\n",
        "                            encoder_hidden_states=torch.cat([norm_hidden_states] + self.bank, dim=1),\n",
        "                            # attention_mask=attention_mask,\n",
        "                            **cross_attention_kwargs,\n",
        "                        )\n",
        "                        attn_output_c = attn_output_uc.clone()\n",
        "                        if do_classifier_free_guidance and style_fidelity > 0:\n",
        "                            attn_output_c[uc_mask] = self.attn1(\n",
        "                                norm_hidden_states[uc_mask],\n",
        "                                encoder_hidden_states=norm_hidden_states[uc_mask],\n",
        "                                **cross_attention_kwargs,\n",
        "                            )\n",
        "                        attn_output = style_fidelity * attn_output_c + (1.0 - style_fidelity) * attn_output_uc\n",
        "                        self.bank.clear()\n",
        "                    else:\n",
        "                        attn_output = self.attn1(\n",
        "                            norm_hidden_states,\n",
        "                            encoder_hidden_states=encoder_hidden_states if self.only_cross_attention else None,\n",
        "                            attention_mask=attention_mask,\n",
        "                            **cross_attention_kwargs,\n",
        "                        )\n",
        "            if self.use_ada_layer_norm_zero:\n",
        "                attn_output = gate_msa.unsqueeze(1) * attn_output\n",
        "            hidden_states = attn_output + hidden_states\n",
        "\n",
        "            if self.attn2 is not None:\n",
        "                norm_hidden_states = (\n",
        "                    self.norm2(hidden_states, timestep) if self.use_ada_layer_norm else self.norm2(hidden_states)\n",
        "                )\n",
        "\n",
        "                # 2. Cross-Attention\n",
        "                attn_output = self.attn2(\n",
        "                    norm_hidden_states,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    attention_mask=encoder_attention_mask,\n",
        "                    **cross_attention_kwargs,\n",
        "                )\n",
        "                hidden_states = attn_output + hidden_states\n",
        "\n",
        "            # 3. Feed-forward\n",
        "            norm_hidden_states = self.norm3(hidden_states)\n",
        "\n",
        "            if self.use_ada_layer_norm_zero:\n",
        "                norm_hidden_states = norm_hidden_states * (1 + scale_mlp[:, None]) + shift_mlp[:, None]\n",
        "\n",
        "            ff_output = self.ff(norm_hidden_states)\n",
        "\n",
        "            if self.use_ada_layer_norm_zero:\n",
        "                ff_output = gate_mlp.unsqueeze(1) * ff_output\n",
        "\n",
        "            hidden_states = ff_output + hidden_states\n",
        "\n",
        "            return hidden_states\n",
        "\n",
        "        def hacked_mid_forward(self, *args, **kwargs):\n",
        "            eps = 1e-6\n",
        "            x = self.original_forward(*args, **kwargs)\n",
        "            if MODE == \"write\":\n",
        "                if gn_auto_machine_weight >= self.gn_weight:\n",
        "                    var, mean = torch.var_mean(x, dim=(2, 3), keepdim=True, correction=0)\n",
        "                    self.mean_bank.append(mean)\n",
        "                    self.var_bank.append(var)\n",
        "            if MODE == \"read\":\n",
        "                if len(self.mean_bank) > 0 and len(self.var_bank) > 0:\n",
        "                    var, mean = torch.var_mean(x, dim=(2, 3), keepdim=True, correction=0)\n",
        "                    std = torch.maximum(var, torch.zeros_like(var) + eps) ** 0.5\n",
        "                    mean_acc = sum(self.mean_bank) / float(len(self.mean_bank))\n",
        "                    var_acc = sum(self.var_bank) / float(len(self.var_bank))\n",
        "                    std_acc = torch.maximum(var_acc, torch.zeros_like(var_acc) + eps) ** 0.5\n",
        "                    x_uc = (((x - mean) / std) * std_acc) + mean_acc\n",
        "                    x_c = x_uc.clone()\n",
        "                    if do_classifier_free_guidance and style_fidelity > 0:\n",
        "                        x_c[uc_mask] = x[uc_mask]\n",
        "                    x = style_fidelity * x_c + (1.0 - style_fidelity) * x_uc\n",
        "                self.mean_bank = []\n",
        "                self.var_bank = []\n",
        "            return x\n",
        "\n",
        "        def hack_CrossAttnDownBlock2D_forward(\n",
        "            self,\n",
        "            hidden_states: torch.FloatTensor,\n",
        "            temb: Optional[torch.FloatTensor] = None,\n",
        "            encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "            attention_mask: Optional[torch.FloatTensor] = None,\n",
        "            cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
        "            encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        ):\n",
        "            eps = 1e-6\n",
        "\n",
        "            # TODO(Patrick, William) - attention mask is not used\n",
        "            output_states = ()\n",
        "\n",
        "            for i, (resnet, attn) in enumerate(zip(self.resnets, self.attentions)):\n",
        "                hidden_states = resnet(hidden_states, temb)\n",
        "                hidden_states = attn(\n",
        "                    hidden_states,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    cross_attention_kwargs=cross_attention_kwargs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    encoder_attention_mask=encoder_attention_mask,\n",
        "                    return_dict=False,\n",
        "                )[0]\n",
        "                if MODE == \"write\":\n",
        "                    if gn_auto_machine_weight >= self.gn_weight:\n",
        "                        var, mean = torch.var_mean(hidden_states, dim=(2, 3), keepdim=True, correction=0)\n",
        "                        self.mean_bank.append([mean])\n",
        "                        self.var_bank.append([var])\n",
        "                if MODE == \"read\":\n",
        "                    if len(self.mean_bank) > 0 and len(self.var_bank) > 0:\n",
        "                        var, mean = torch.var_mean(hidden_states, dim=(2, 3), keepdim=True, correction=0)\n",
        "                        std = torch.maximum(var, torch.zeros_like(var) + eps) ** 0.5\n",
        "                        mean_acc = sum(self.mean_bank[i]) / float(len(self.mean_bank[i]))\n",
        "                        var_acc = sum(self.var_bank[i]) / float(len(self.var_bank[i]))\n",
        "                        std_acc = torch.maximum(var_acc, torch.zeros_like(var_acc) + eps) ** 0.5\n",
        "                        hidden_states_uc = (((hidden_states - mean) / std) * std_acc) + mean_acc\n",
        "                        hidden_states_c = hidden_states_uc.clone()\n",
        "                        if do_classifier_free_guidance and style_fidelity > 0:\n",
        "                            hidden_states_c[uc_mask] = hidden_states[uc_mask]\n",
        "                        hidden_states = style_fidelity * hidden_states_c + (1.0 - style_fidelity) * hidden_states_uc\n",
        "\n",
        "                output_states = output_states + (hidden_states,)\n",
        "\n",
        "            if MODE == \"read\":\n",
        "                self.mean_bank = []\n",
        "                self.var_bank = []\n",
        "\n",
        "            if self.downsamplers is not None:\n",
        "                for downsampler in self.downsamplers:\n",
        "                    hidden_states = downsampler(hidden_states)\n",
        "\n",
        "                output_states = output_states + (hidden_states,)\n",
        "\n",
        "            return hidden_states, output_states\n",
        "\n",
        "        def hacked_DownBlock2D_forward(self, hidden_states, temb=None):\n",
        "            eps = 1e-6\n",
        "\n",
        "            output_states = ()\n",
        "\n",
        "            for i, resnet in enumerate(self.resnets):\n",
        "                hidden_states = resnet(hidden_states, temb)\n",
        "\n",
        "                if MODE == \"write\":\n",
        "                    if gn_auto_machine_weight >= self.gn_weight:\n",
        "                        var, mean = torch.var_mean(hidden_states, dim=(2, 3), keepdim=True, correction=0)\n",
        "                        self.mean_bank.append([mean])\n",
        "                        self.var_bank.append([var])\n",
        "                if MODE == \"read\":\n",
        "                    if len(self.mean_bank) > 0 and len(self.var_bank) > 0:\n",
        "                        var, mean = torch.var_mean(hidden_states, dim=(2, 3), keepdim=True, correction=0)\n",
        "                        std = torch.maximum(var, torch.zeros_like(var) + eps) ** 0.5\n",
        "                        mean_acc = sum(self.mean_bank[i]) / float(len(self.mean_bank[i]))\n",
        "                        var_acc = sum(self.var_bank[i]) / float(len(self.var_bank[i]))\n",
        "                        std_acc = torch.maximum(var_acc, torch.zeros_like(var_acc) + eps) ** 0.5\n",
        "                        hidden_states_uc = (((hidden_states - mean) / std) * std_acc) + mean_acc\n",
        "                        hidden_states_c = hidden_states_uc.clone()\n",
        "                        if do_classifier_free_guidance and style_fidelity > 0:\n",
        "                            hidden_states_c[uc_mask] = hidden_states[uc_mask]\n",
        "                        hidden_states = style_fidelity * hidden_states_c + (1.0 - style_fidelity) * hidden_states_uc\n",
        "\n",
        "                output_states = output_states + (hidden_states,)\n",
        "\n",
        "            if MODE == \"read\":\n",
        "                self.mean_bank = []\n",
        "                self.var_bank = []\n",
        "\n",
        "            if self.downsamplers is not None:\n",
        "                for downsampler in self.downsamplers:\n",
        "                    hidden_states = downsampler(hidden_states)\n",
        "\n",
        "                output_states = output_states + (hidden_states,)\n",
        "\n",
        "            return hidden_states, output_states\n",
        "\n",
        "        def hacked_CrossAttnUpBlock2D_forward(\n",
        "            self,\n",
        "            hidden_states: torch.FloatTensor,\n",
        "            res_hidden_states_tuple: Tuple[torch.FloatTensor, ...],\n",
        "            temb: Optional[torch.FloatTensor] = None,\n",
        "            encoder_hidden_states: Optional[torch.FloatTensor] = None,\n",
        "            cross_attention_kwargs: Optional[Dict[str, Any]] = None,\n",
        "            upsample_size: Optional[int] = None,\n",
        "            attention_mask: Optional[torch.FloatTensor] = None,\n",
        "            encoder_attention_mask: Optional[torch.FloatTensor] = None,\n",
        "        ):\n",
        "            eps = 1e-6\n",
        "            # TODO(Patrick, William) - attention mask is not used\n",
        "            for i, (resnet, attn) in enumerate(zip(self.resnets, self.attentions)):\n",
        "                # pop res hidden states\n",
        "                res_hidden_states = res_hidden_states_tuple[-1]\n",
        "                res_hidden_states_tuple = res_hidden_states_tuple[:-1]\n",
        "                hidden_states = torch.cat([hidden_states, res_hidden_states], dim=1)\n",
        "                hidden_states = resnet(hidden_states, temb)\n",
        "                hidden_states = attn(\n",
        "                    hidden_states,\n",
        "                    encoder_hidden_states=encoder_hidden_states,\n",
        "                    cross_attention_kwargs=cross_attention_kwargs,\n",
        "                    attention_mask=attention_mask,\n",
        "                    encoder_attention_mask=encoder_attention_mask,\n",
        "                    return_dict=False,\n",
        "                )[0]\n",
        "\n",
        "                if MODE == \"write\":\n",
        "                    if gn_auto_machine_weight >= self.gn_weight:\n",
        "                        var, mean = torch.var_mean(hidden_states, dim=(2, 3), keepdim=True, correction=0)\n",
        "                        self.mean_bank.append([mean])\n",
        "                        self.var_bank.append([var])\n",
        "                if MODE == \"read\":\n",
        "                    if len(self.mean_bank) > 0 and len(self.var_bank) > 0:\n",
        "                        var, mean = torch.var_mean(hidden_states, dim=(2, 3), keepdim=True, correction=0)\n",
        "                        std = torch.maximum(var, torch.zeros_like(var) + eps) ** 0.5\n",
        "                        mean_acc = sum(self.mean_bank[i]) / float(len(self.mean_bank[i]))\n",
        "                        var_acc = sum(self.var_bank[i]) / float(len(self.var_bank[i]))\n",
        "                        std_acc = torch.maximum(var_acc, torch.zeros_like(var_acc) + eps) ** 0.5\n",
        "                        hidden_states_uc = (((hidden_states - mean) / std) * std_acc) + mean_acc\n",
        "                        hidden_states_c = hidden_states_uc.clone()\n",
        "                        if do_classifier_free_guidance and style_fidelity > 0:\n",
        "                            hidden_states_c[uc_mask] = hidden_states[uc_mask]\n",
        "                        hidden_states = style_fidelity * hidden_states_c + (1.0 - style_fidelity) * hidden_states_uc\n",
        "\n",
        "            if MODE == \"read\":\n",
        "                self.mean_bank = []\n",
        "                self.var_bank = []\n",
        "\n",
        "            if self.upsamplers is not None:\n",
        "                for upsampler in self.upsamplers:\n",
        "                    hidden_states = upsampler(hidden_states, upsample_size)\n",
        "\n",
        "            return hidden_states\n",
        "\n",
        "        def hacked_UpBlock2D_forward(self, hidden_states, res_hidden_states_tuple, temb=None, upsample_size=None):\n",
        "            eps = 1e-6\n",
        "            for i, resnet in enumerate(self.resnets):\n",
        "                # pop res hidden states\n",
        "                res_hidden_states = res_hidden_states_tuple[-1]\n",
        "                res_hidden_states_tuple = res_hidden_states_tuple[:-1]\n",
        "                hidden_states = torch.cat([hidden_states, res_hidden_states], dim=1)\n",
        "                hidden_states = resnet(hidden_states, temb)\n",
        "\n",
        "                if MODE == \"write\":\n",
        "                    if gn_auto_machine_weight >= self.gn_weight:\n",
        "                        var, mean = torch.var_mean(hidden_states, dim=(2, 3), keepdim=True, correction=0)\n",
        "                        self.mean_bank.append([mean])\n",
        "                        self.var_bank.append([var])\n",
        "                if MODE == \"read\":\n",
        "                    if len(self.mean_bank) > 0 and len(self.var_bank) > 0:\n",
        "                        var, mean = torch.var_mean(hidden_states, dim=(2, 3), keepdim=True, correction=0)\n",
        "                        std = torch.maximum(var, torch.zeros_like(var) + eps) ** 0.5\n",
        "                        mean_acc = sum(self.mean_bank[i]) / float(len(self.mean_bank[i]))\n",
        "                        var_acc = sum(self.var_bank[i]) / float(len(self.var_bank[i]))\n",
        "                        std_acc = torch.maximum(var_acc, torch.zeros_like(var_acc) + eps) ** 0.5\n",
        "                        hidden_states_uc = (((hidden_states - mean) / std) * std_acc) + mean_acc\n",
        "                        hidden_states_c = hidden_states_uc.clone()\n",
        "                        if do_classifier_free_guidance and style_fidelity > 0:\n",
        "                            hidden_states_c[uc_mask] = hidden_states[uc_mask]\n",
        "                        hidden_states = style_fidelity * hidden_states_c + (1.0 - style_fidelity) * hidden_states_uc\n",
        "\n",
        "            if MODE == \"read\":\n",
        "                self.mean_bank = []\n",
        "                self.var_bank = []\n",
        "\n",
        "            if self.upsamplers is not None:\n",
        "                for upsampler in self.upsamplers:\n",
        "                    hidden_states = upsampler(hidden_states, upsample_size)\n",
        "\n",
        "            return hidden_states\n",
        "\n",
        "        if reference_attn:\n",
        "            attn_modules = [module for module in torch_dfs(self.unet) if isinstance(module, BasicTransformerBlock)]\n",
        "            attn_modules = sorted(attn_modules, key=lambda x: -x.norm1.normalized_shape[0])\n",
        "\n",
        "            for i, module in enumerate(attn_modules):\n",
        "                module._original_inner_forward = module.forward\n",
        "                module.forward = hacked_basic_transformer_inner_forward.__get__(module, BasicTransformerBlock)\n",
        "                module.bank = []\n",
        "                module.attn_weight = float(i) / float(len(attn_modules))\n",
        "\n",
        "        if reference_adain:\n",
        "            gn_modules = [self.unet.mid_block]\n",
        "            self.unet.mid_block.gn_weight = 0\n",
        "\n",
        "            down_blocks = self.unet.down_blocks\n",
        "            for w, module in enumerate(down_blocks):\n",
        "                module.gn_weight = 1.0 - float(w) / float(len(down_blocks))\n",
        "                gn_modules.append(module)\n",
        "\n",
        "            up_blocks = self.unet.up_blocks\n",
        "            for w, module in enumerate(up_blocks):\n",
        "                module.gn_weight = float(w) / float(len(up_blocks))\n",
        "                gn_modules.append(module)\n",
        "\n",
        "            for i, module in enumerate(gn_modules):\n",
        "                if getattr(module, \"original_forward\", None) is None:\n",
        "                    module.original_forward = module.forward\n",
        "                if i == 0:\n",
        "                    # mid_block\n",
        "                    module.forward = hacked_mid_forward.__get__(module, torch.nn.Module)\n",
        "                elif isinstance(module, CrossAttnDownBlock2D):\n",
        "                    module.forward = hack_CrossAttnDownBlock2D_forward.__get__(module, CrossAttnDownBlock2D)\n",
        "                elif isinstance(module, DownBlock2D):\n",
        "                    module.forward = hacked_DownBlock2D_forward.__get__(module, DownBlock2D)\n",
        "                elif isinstance(module, CrossAttnUpBlock2D):\n",
        "                    module.forward = hacked_CrossAttnUpBlock2D_forward.__get__(module, CrossAttnUpBlock2D)\n",
        "                elif isinstance(module, UpBlock2D):\n",
        "                    module.forward = hacked_UpBlock2D_forward.__get__(module, UpBlock2D)\n",
        "                module.mean_bank = []\n",
        "                module.var_bank = []\n",
        "                module.gn_weight *= 2\n",
        "\n",
        "        # 11. Denoising loop\n",
        "        num_warmup_steps = len(timesteps) - num_inference_steps * self.scheduler.order\n",
        "        with self.progress_bar(total=num_inference_steps) as progress_bar:\n",
        "            for i, t in enumerate(timesteps):\n",
        "                # expand the latents if we are doing classifier free guidance\n",
        "                latent_model_input = torch.cat([latents] * 2) if do_classifier_free_guidance else latents\n",
        "                latent_model_input = self.scheduler.scale_model_input(latent_model_input, t)\n",
        "\n",
        "                # controlnet(s) inference\n",
        "                if guess_mode and do_classifier_free_guidance:\n",
        "                    # Infer ControlNet only for the conditional batch.\n",
        "                    control_model_input = latents\n",
        "                    control_model_input = self.scheduler.scale_model_input(control_model_input, t)\n",
        "                    controlnet_prompt_embeds = prompt_embeds.chunk(2)[1]\n",
        "                else:\n",
        "                    control_model_input = latent_model_input\n",
        "                    controlnet_prompt_embeds = prompt_embeds\n",
        "\n",
        "                down_block_res_samples, mid_block_res_sample = self.controlnet(\n",
        "                    control_model_input,\n",
        "                    t,\n",
        "                    encoder_hidden_states=controlnet_prompt_embeds,\n",
        "                    controlnet_cond=image,\n",
        "                    conditioning_scale=controlnet_conditioning_scale,\n",
        "                    guess_mode=guess_mode,\n",
        "                    return_dict=False,\n",
        "                )\n",
        "\n",
        "                if guess_mode and do_classifier_free_guidance:\n",
        "                    # Infered ControlNet only for the conditional batch.\n",
        "                    # To apply the output of ControlNet to both the unconditional and conditional batches,\n",
        "                    # add 0 to the unconditional batch to keep it unchanged.\n",
        "                    down_block_res_samples = [torch.cat([torch.zeros_like(d), d]) for d in down_block_res_samples]\n",
        "                    mid_block_res_sample = torch.cat([torch.zeros_like(mid_block_res_sample), mid_block_res_sample])\n",
        "\n",
        "                # ref only part\n",
        "                noise = randn_tensor(\n",
        "                    ref_image_latents.shape, generator=generator, device=device, dtype=ref_image_latents.dtype\n",
        "                )\n",
        "                ref_xt = self.scheduler.add_noise(\n",
        "                    ref_image_latents,\n",
        "                    noise,\n",
        "                    t.reshape(\n",
        "                        1,\n",
        "                    ),\n",
        "                )\n",
        "                ref_xt = self.scheduler.scale_model_input(ref_xt, t)\n",
        "\n",
        "                MODE = \"write\"\n",
        "                self.unet(\n",
        "                    ref_xt,\n",
        "                    t,\n",
        "                    encoder_hidden_states=prompt_embeds,\n",
        "                    cross_attention_kwargs=cross_attention_kwargs,\n",
        "                    return_dict=False,\n",
        "                )\n",
        "\n",
        "                # predict the noise residual\n",
        "                MODE = \"read\"\n",
        "                noise_pred = self.unet(\n",
        "                    latent_model_input,\n",
        "                    t,\n",
        "                    encoder_hidden_states=prompt_embeds,\n",
        "                    cross_attention_kwargs=cross_attention_kwargs,\n",
        "                    down_block_additional_residuals=down_block_res_samples,\n",
        "                    mid_block_additional_residual=mid_block_res_sample,\n",
        "                    return_dict=False,\n",
        "                )[0]\n",
        "\n",
        "                # perform guidance\n",
        "                if do_classifier_free_guidance:\n",
        "                    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
        "                    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "                # compute the previous noisy sample x_t -> x_t-1\n",
        "                latents = self.scheduler.step(noise_pred, t, latents, **extra_step_kwargs, return_dict=False)[0]\n",
        "\n",
        "                # call the callback, if provided\n",
        "                if i == len(timesteps) - 1 or ((i + 1) > num_warmup_steps and (i + 1) % self.scheduler.order == 0):\n",
        "                    progress_bar.update()\n",
        "                    if callback is not None and i % callback_steps == 0:\n",
        "                        callback(i, t, latents)\n",
        "\n",
        "        # If we do sequential model offloading, let's offload unet and controlnet\n",
        "        # manually for max memory savings\n",
        "        if hasattr(self, \"final_offload_hook\") and self.final_offload_hook is not None:\n",
        "            self.unet.to(\"cpu\")\n",
        "            self.controlnet.to(\"cpu\")\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        if not output_type == \"latent\":\n",
        "            image = self.vae.decode(latents / self.vae.config.scaling_factor, return_dict=False)[0]\n",
        "            image, has_nsfw_concept = self.run_safety_checker(image, device, prompt_embeds.dtype)\n",
        "        else:\n",
        "            image = latents\n",
        "            has_nsfw_concept = None\n",
        "\n",
        "        if has_nsfw_concept is None:\n",
        "            do_denormalize = [True] * image.shape[0]\n",
        "        else:\n",
        "            do_denormalize = [not has_nsfw for has_nsfw in has_nsfw_concept]\n",
        "\n",
        "        image = self.image_processor.postprocess(image, output_type=output_type, do_denormalize=do_denormalize)\n",
        "\n",
        "        # Offload last model to CPU\n",
        "        if hasattr(self, \"final_offload_hook\") and self.final_offload_hook is not None:\n",
        "            self.final_offload_hook.offload()\n",
        "\n",
        "        if not return_dict:\n",
        "            return (image, has_nsfw_concept)\n",
        "\n",
        "        return StableDiffusionPipelineOutput(images=image, nsfw_content_detected=has_nsfw_concept)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "1UKv41g0p9X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Parametrages\n",
        "\n",
        "# @markdown Use the \"ensemble of expert model\" staking method for images generation\n",
        "MAX_SEED = np.iinfo(np.int32).max\n",
        "\n",
        "# @markdown Memory saving (longer rendering) options\n",
        "USE_TORCH_COMPILE = False # @param {type:\"boolean\"}\n",
        "ENABLE_REFINER = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown Sampler\n",
        "scheduler = UniPCMultistepScheduler # @param [\"UniPCMultistepScheduler\", \"DDIMScheduler\", \"LMSDiscreteScheduler\", \"PNDMScheduler\"] {type:\"raw\"}\n",
        "\n",
        "# Loads the ControlNet Openpose model\n",
        "cn_openpose = ControlNetModel.from_pretrained(\n",
        "    \"P2Enjoy/photomaton_controlnet_openpose\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    variant='fp16'\n",
        ")\n",
        "cn_openpose.set_attention_slice(\"max\");\n",
        "controlnets = [\n",
        "  cn_openpose\n",
        "]\n",
        "\n",
        "pipe = None\n",
        "refiner = None\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def apply_args(model: DiffusionPipeline, enable_xformers_model, enable_xformers_vae, enable_vae_slicing, enable_vae_tiling, use_torch_compile, enable_cpu_offload, enable_cpu_seq_offload) -> StableDiffusionControlNetPipeline:\n",
        "  # Configuration du sampler\n",
        "  model.scheduler = scheduler.from_config(model.scheduler.config)\n",
        "  if enable_xformers_model:\n",
        "    print(\"Model XFormers Enabled\")\n",
        "    model.enable_xformers_memory_efficient_attention()\n",
        "  if enable_xformers_vae:\n",
        "    print(\"VAE XFormers Enabled\")\n",
        "    model.vae.enable_xformers_memory_efficient_attention()\n",
        "  else:\n",
        "    model.enable_attention_slicing();\n",
        "  if enable_vae_slicing:\n",
        "    print(\"VAE Slicing Enabled\")\n",
        "    model.enable_vae_slicing()\n",
        "  if enable_vae_tiling:\n",
        "    print(\"VAE Tiling Enabled\")\n",
        "    model.enable_vae_tiling()\n",
        "  if use_torch_compile:\n",
        "    print(\"Torch Compile Enabled\")\n",
        "    model.unet = torch.compile(\n",
        "      model.unet,\n",
        "      mode='reduce-overhead',\n",
        "      fullgraph=True\n",
        "    )\n",
        "  if enable_cpu_offload or enable_cpu_seq_offload:\n",
        "    if enable_cpu_offload:\n",
        "      print(\"CPU Offload Enabled\")\n",
        "      model.enable_model_cpu_offload()\n",
        "    if enable_cpu_seq_offload:\n",
        "      print(\"CPU Sequential Offload Enabled\")\n",
        "      model.enable_sequential_cpu_offload()\n",
        "  else:\n",
        "    model.to(device)\n",
        "  return model;\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  vae_fix = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-mse\", torch_dtype=torch.float16)\n",
        "\n",
        "  #StableDiffusionControlNetPipeline\n",
        "  #StableDiffusionControlNetReferencePipeline\n",
        "  pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "        'P2Enjoy/photomaton_mainmodel',\n",
        "        controlnet=controlnets,\n",
        "        vae=vae_fix,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        add_watermarker=False,\n",
        "        variant='fp16');\n",
        "  apply_args(\n",
        "      model=pipe,\n",
        "      enable_xformers_model=True,\n",
        "      enable_xformers_vae=False,\n",
        "      enable_vae_slicing=True,\n",
        "      enable_vae_tiling=True,\n",
        "      use_torch_compile=USE_TORCH_COMPILE,\n",
        "      enable_cpu_offload=False,\n",
        "      enable_cpu_seq_offload=True\n",
        "  );\n",
        "\n",
        "  if ENABLE_REFINER:\n",
        "    ref_vae_fix = AutoencoderKL.from_pretrained(\"madebyollin/sdxl-vae-fp16-fix\", torch_dtype=torch.float16)\n",
        "    refiner = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "        'stabilityai/stable-diffusion-xl-refiner-1.0',\n",
        "        vae=ref_vae_fix,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        add_watermarker=False,\n",
        "        variant='fp16');\n",
        "    apply_args(\n",
        "        model=refiner,\n",
        "        enable_xformers_model=True,\n",
        "        enable_xformers_vae=False,\n",
        "        enable_vae_slicing=True,\n",
        "        enable_vae_tiling=True,\n",
        "        use_torch_compile=USE_TORCH_COMPILE,\n",
        "        enable_cpu_offload=False,\n",
        "        enable_cpu_seq_offload=False\n",
        "    );\n",
        "else:\n",
        "  pipe = None\n",
        "  refiner = None\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "Glny7Rw--1Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Paramtres de gnration\n",
        "guidance_scale_base = 5.5 # @param {type:\"slider\", min:1, max:20, step:0.5}\n",
        "guidance_scale_refiner = 11.5 # @param {type:\"slider\", min:1, max:20, step:0.5}\n",
        "width = 768 # @param {type:\"slider\", min:512, max:2048, step:64}\n",
        "height = 1408 # @param {type:\"slider\", min:512, max:2048, step:64}\n",
        "num_inference_steps = 50 # @param {type:\"slider\", min:10, max:100, step:5}\n",
        "num_images_per_prompt = 1 # @param {type:\"slider\", min:1, max:8, step:1}\n",
        "high_noise_frac = 0.9 # @param {type:\"slider\", min:0.05, max:1, step:0.05}\n",
        "controlnet_conditionning_scale = 0.5 # @param {type:\"slider\", min:0.05, max:1, step:0.05}\n",
        "seed = 0 # @param {type:\"integer\"}\n",
        "# @markdown Positive and negative prompt to text encoder (defaults to \"OAI CLIP-ViT/L-14\")\n",
        "prompt_1 = \"RAW photo, (photoshoot, professionnal photoshoot, portrait, person in a tuxedo facing the camera), 8k uhd, dslr, soft lighting, high quality, film grain, Fujifilm XT3\" # @param {type:\"string\"}\n",
        "negative_prompt_1 = \"(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, mutated hands and fingers:1.4), (deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, wrong anatomy, extra limb, missing limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting, amputation\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "wlQWkdqaV138",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt_1: str,\n",
        "             negative_prompt_1: str,\n",
        "             num_images_per_prompt: int,\n",
        "             controlnet_images,\n",
        "             webcam_picture,\n",
        "             seed: int,\n",
        "             width: int,\n",
        "             height: int,\n",
        "             guidance_scale_base: float,\n",
        "             high_noise_frac: float,\n",
        "             controlnet_conditionning_scale: float,\n",
        "             num_inference_steps_base: int) -> PIL.Image.Image:\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    generator = torch.Generator().manual_seed(seed)\n",
        "    output_type = 'pil';\n",
        "\n",
        "    step1 = pipe(prompt=prompt_1,\n",
        "                negative_prompt=negative_prompt_1,\n",
        "                image= controlnet_images,\n",
        "                #ref_image=webcam_picture,\n",
        "                #reference_attn=True,\n",
        "                #reference_adain=False,\n",
        "                #guess_mode=True,\n",
        "                width=width,\n",
        "                height=height,\n",
        "                guidance_scale=guidance_scale_base,\n",
        "                num_inference_steps=int(num_inference_steps_base * high_noise_frac),\n",
        "                generator=generator,\n",
        "                num_images_per_prompt=num_images_per_prompt,\n",
        "                controlnet_conditioning_scale=[controlnet_conditionning_scale],\n",
        "                output_type=output_type);\n",
        "\n",
        "    return step1;\n",
        "\n",
        "print ('Base model warmup lap...')\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "generate(prompt_1= 'test',\n",
        "             negative_prompt_1= '',\n",
        "             num_images_per_prompt= 1,\n",
        "             controlnet_images= [Image.new('RGB', (64, 64), 'black')],\n",
        "             webcam_picture= [Image.new('RGB', (64, 64), 'black')],\n",
        "             seed= 0,\n",
        "             width= 64,\n",
        "             height=64,\n",
        "             guidance_scale_base= 1.0,\n",
        "             high_noise_frac= 1.0,\n",
        "             controlnet_conditionning_scale= 0.0,\n",
        "             num_inference_steps_base= 1);"
      ],
      "metadata": {
        "id": "xZZlt251EtS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refine(latent,\n",
        "           prompt_1: str,\n",
        "           negative_prompt_1: str,\n",
        "           num_images_per_prompt: int,\n",
        "           controlnet_images,\n",
        "           seed: int,\n",
        "           width: int,\n",
        "           height: int,\n",
        "           guidance_scale_refiner: float,\n",
        "           high_noise_frac: float,\n",
        "           controlnet_conditionning_scale: float,\n",
        "           num_inference_steps_refiner: int) -> PIL.Image.Image:\n",
        "\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    generator = torch.Generator().manual_seed(seed)\n",
        "    output_type = 'pil';\n",
        "    step2 = refiner(prompt=prompt_1,\n",
        "                    negative_prompt=negative_prompt_1,\n",
        "                    guidance_scale=guidance_scale_refiner,\n",
        "                    num_inference_steps=num_inference_steps_refiner,\n",
        "                    denoising_start=high_noise_frac,\n",
        "                    image=latent,\n",
        "                    num_images_per_prompt=num_images_per_prompt,\n",
        "                    generator=generator)\n",
        "\n",
        "    return step2;\n",
        "\n",
        "\n",
        "if ENABLE_REFINER:\n",
        "  print ('Refiner warmup lap...')\n",
        "  refine(latent= Image.new('RGB', (64, 64), 'white'),\n",
        "      prompt_1= 'test',\n",
        "      negative_prompt_1= '',\n",
        "      num_images_per_prompt= 1,\n",
        "      controlnet_images= [Image.new('RGB', (64, 64), 'white')],\n",
        "      seed= 0,\n",
        "      width= 64,\n",
        "      height=64,\n",
        "      guidance_scale_refiner= 1.0,\n",
        "      high_noise_frac= 1.0,\n",
        "      controlnet_conditionning_scale= 0.0,\n",
        "      num_inference_steps_base= 1);"
      ],
      "metadata": {
        "id": "AjJla28iVsZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_align = True #@param {type:\"boolean\"}\n",
        "face_upsample = True #@param {type:\"boolean\"}\n",
        "background_enhance = False #@param {type:\"boolean\"}\n",
        "upscale = 1 #@param {type:\"slider\", min:1, max:4, step:1}\n",
        "codeformer_fidelity = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "\n",
        "def landmark_codeformer(_images, landmarks_source):\n",
        "  cf_images = []\n",
        "  model_path = get_models()[0];\n",
        "  for image in _images:\n",
        "    lm_image = swap_landmarks(landmarks_source, image, model_path)\n",
        "    cf_image = codeformer(\n",
        "        image=lm_image,\n",
        "        face_align=face_align,\n",
        "        face_upsample=face_upsample,\n",
        "        background_enhance=background_enhance,\n",
        "        upscale=upscale,\n",
        "        codeformer_fidelity=codeformer_fidelity\n",
        "    )\n",
        "    cf_images.append(cf_image)\n",
        "  return cf_images;"
      ],
      "metadata": {
        "id": "5yfnglNvFVjK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_grid(imgs):\n",
        "    n = len(imgs)\n",
        "\n",
        "    # Determine rows and cols based on number of images\n",
        "    if n == 1:\n",
        "        rows, cols = 1, 1\n",
        "    elif n == 2:\n",
        "        rows, cols = 1, 2\n",
        "    elif n <= 4:\n",
        "        rows, cols = 2, 2\n",
        "    else:\n",
        "        rows, cols = 2, 4\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = PIL.Image.new(\"RGB\", size=(cols * w, rows * h))\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid"
      ],
      "metadata": {
        "id": "QEBa-f9ZURBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interface utilisateur"
      ],
      "metadata": {
        "id": "35026VMLuSuO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "pip install gradio"
      ],
      "metadata": {
        "id": "WDDuqRoOuXdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "def combine_images(pose, webcam, prompt):\n",
        "    # Open the images using PIL\n",
        "    # pose = Image.open(pose)\n",
        "    landmarks_source = webcam\n",
        "    controlnet_images = [pose]\n",
        "\n",
        "    gen_images= generate(\n",
        "      prompt_1= prompt + \", \" + prompt_1,\n",
        "      negative_prompt_1= negative_prompt_1,\n",
        "      controlnet_images= controlnet_images,\n",
        "      webcam_picture= landmarks_source,\n",
        "      num_images_per_prompt= num_images_per_prompt,\n",
        "      seed= seed,\n",
        "      width= width,\n",
        "      height= height,\n",
        "      guidance_scale_base= guidance_scale_base,\n",
        "      high_noise_frac= high_noise_frac,\n",
        "      controlnet_conditionning_scale= controlnet_conditionning_scale,\n",
        "      num_inference_steps_base= num_inference_steps\n",
        "    );\n",
        "\n",
        "    if ENABLE_REFINER:\n",
        "      gen_images= refine(\n",
        "        latent= gen_images.images,\n",
        "        prompt_1= prompt_1,\n",
        "        negative_prompt_1= negative_prompt_1,\n",
        "        controlnet_images= controlnet_images,\n",
        "        num_images_per_prompt= num_images_per_prompt,\n",
        "        seed= seed,\n",
        "        width= width,\n",
        "        height= height,\n",
        "        guidance_scale_refiner= guidance_scale_refiner,\n",
        "        high_noise_frac= high_noise_frac,\n",
        "        controlnet_conditionning_scale= controlnet_conditionning_scale,\n",
        "        num_inference_steps_refiner= num_inference_steps\n",
        "    );\n",
        "\n",
        "    cflm_images= landmark_codeformer(gen_images.images, landmarks_source)\n",
        "    final_render= image_grid(cflm_images)\n",
        "\n",
        "    return final_render\n",
        "\n",
        "# Define the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=combine_images,\n",
        "    inputs=[gr.Image(type=\"pil\"), gr.Image(type=\"pil\")],\n",
        "    outputs=[gr.Image(type=\"pil\")],\n",
        "    live=False\n",
        ")"
      ],
      "metadata": {
        "id": "pbs2Rz8nuWD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Magic happens here"
      ],
      "metadata": {
        "id": "eGHJ7MRAkBiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch(debug=True, share=True)"
      ],
      "metadata": {
        "id": "sHgYIv_3jHND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "controlnet_images = load_image(\"https://openposes-storage.s3.ca-central-1.amazonaws.com/poses/transparent/standing_01.png\")\n",
        "landmarks_source = load_image(\"https://media.licdn.com/dms/image/D4D03AQF9hpsvt_7s3A/profile-displayphoto-shrink_800_800/0/1681884109435?e=1699488000&v=beta&t=FV7ZHzmxRpVzNGcGy-pJjFYUwas7_L0fU5rUiqIsChc\")\n",
        "\n",
        "scheduler = UniPCMultistepScheduler # @param [\"UniPCMultistepScheduler\", \"DDIMScheduler\", \"LMSDiscreteScheduler\", \"PNDMScheduler\"] {type:\"raw\"}\n",
        "pipe.scheduler = scheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "generator = torch.Generator().manual_seed(0);\n",
        "gen_images= pipe(prompt=prompt_1,\n",
        "                negative_prompt=negative_prompt_1,\n",
        "                ref_image=landmarks_source,\n",
        "                image= [controlnet_images],\n",
        "                reference_attn=True,\n",
        "                reference_adain=True,\n",
        "                guess_mode=True,\n",
        "                width=width,\n",
        "                height=height,\n",
        "                guidance_scale=7.5,\n",
        "                num_inference_steps=60,\n",
        "                generator=generator,\n",
        "                num_images_per_prompt=1,\n",
        "                controlnet_conditioning_scale=[1],\n",
        "                output_type='pil');\n",
        "\n",
        "image_grid(gen_images.images)"
      ],
      "metadata": {
        "id": "rIoslpMQG9QU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}